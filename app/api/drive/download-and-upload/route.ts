import { NextRequest, NextResponse } from 'next/server'
import { getDriveClient } from '@/lib/google-drive'
import { uploadBase64ToCloudinary } from '@/lib/cloudinary'
import sharp from 'sharp'
import { GaxiosResponse } from 'gaxios'

export async function POST(req: NextRequest) {
  let attempt = 0
  const maxAttempts = 2
  
  while (attempt < maxAttempts) {
    attempt++
    
    try {
      const { fileId, fileName } = await req.json()

      if (!fileId) {
        return NextResponse.json({ error: 'File ID required' }, { status: 400 })
      }

      // Sanitize filename
      const sanitizedName = (fileName || 'untitled.jpg').replace(/[^\w\s.-]/gi, '_').replace(/\s+/g, '_')
      console.log(`üìÇ [Attempt ${attempt}/${maxAttempts}] Processing: ${sanitizedName}`)

      const drive = getDriveClient()

      if (!drive) {
        return NextResponse.json({ error: 'Google Drive not configured' }, { status: 503 })
      }

      // Download with aggressive timeout and retry
      console.log(`‚¨áÔ∏è Downloading: ${fileId}`)
      let response: GaxiosResponse<ArrayBuffer>
      try {
        response = await drive.files.get(
          { fileId, alt: 'media' },
          { 
            responseType: 'arraybuffer' as 'json', 
            timeout: 90000, // 90 seconds
          }
        ) as GaxiosResponse<ArrayBuffer>
      } catch (downloadError) {
        console.error(`‚ùå Download failed (attempt ${attempt}):`, downloadError)
        if (attempt < maxAttempts) {
          console.log(`üîÑ Retrying in 2 seconds...`)
          await new Promise(resolve => setTimeout(resolve, 2000))
          continue
        }
        throw downloadError
      }

      let buffer: Buffer = Buffer.from(response.data as ArrayBuffer)
      const originalSizeMB = (buffer.length / (1024 * 1024)).toFixed(2)
      console.log(`üì• Downloaded: ${originalSizeMB}MB`)
      
      // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å‡πÜ (>20MB) ‚Üí ‡∏ö‡∏µ‡∏ö‡πÅ‡∏£‡∏á‡∏™‡∏∏‡∏î
      const ext = sanitizedName.toLowerCase().split('.').pop() || 'jpg'
      const isHeic = ext === 'heic' || ext === 'heif'
      const isGif = ext === 'gif'
      const isPng = ext === 'png'
      const isWebp = ext === 'webp'
      
      // GIF ‡πÑ‡∏°‡πà‡∏à‡∏±‡∏ö‡∏¢‡∏∏‡πà‡∏á
      if (isGif) {
        console.log(`üé¨ GIF: Upload as-is`)
        const base64 = buffer.toString('base64')
        const url = await uploadBase64ToCloudinary(`data:image/gif;base64,${base64}`, 'hotelplus-v2')
        return NextResponse.json({ url })
      }
      
      // HEIC ‚Üí ‡πÉ‡∏´‡πâ Cloudinary handle
      if (isHeic) {
        console.log(`üîÑ HEIC: Let Cloudinary convert`)
        const base64 = buffer.toString('base64')
        const url = await uploadBase64ToCloudinary(`data:application/octet-stream;base64,${base64}`, 'hotelplus-v2')
        return NextResponse.json({ url })
      }
      
      // ‡∏£‡∏π‡∏õ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‚Üí ‡∏ö‡∏µ‡∏ö‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î
      let mimeType = 'image/jpeg'
      let maxDimension = 3000
      let quality = 85
      
      // ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà ‚Üí ‡∏ö‡∏µ‡∏ö‡πÅ‡∏£‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
      if (buffer.length > 20 * 1024 * 1024) {
        maxDimension = 2500
        quality = 75
        console.log(`üî• Large file (${originalSizeMB}MB): Aggressive compression`)
      } else if (buffer.length > 10 * 1024 * 1024) {
        maxDimension = 2800
        quality = 80
        console.log(`üîÑ Medium file (${originalSizeMB}MB): Moderate compression`)
      } else {
        console.log(`‚úÖ Small file (${originalSizeMB}MB): Minimal compression`)
      }
      
      try {
        let sharpInstance = sharp(buffer, { failOnError: false })
          .resize(maxDimension, maxDimension, { 
            fit: 'inside', 
            withoutEnlargement: true 
          })
        
        // ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å format
        if (isPng && buffer.length < 5 * 1024 * 1024) {
          // PNG ‡πÄ‡∏•‡πá‡∏Å ‚Üí ‡∏£‡∏±‡∏Å‡∏©‡∏≤ PNG
          sharpInstance = sharpInstance.png({ quality, compressionLevel: 9 })
          mimeType = 'image/png'
        } else if (isWebp) {
          sharpInstance = sharpInstance.webp({ quality })
          mimeType = 'image/webp'
        } else {
          // Default: JPEG (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á)
          sharpInstance = sharpInstance.jpeg({ quality, mozjpeg: true })
          mimeType = 'image/jpeg'
        }
        
        buffer = await sharpInstance.toBuffer()
        let finalSizeMB = (buffer.length / (1024 * 1024)).toFixed(2)
        console.log(`‚úÖ Processed: ${originalSizeMB}MB ‚Üí ${finalSizeMB}MB`)
        
        // üî• Cloudinary Base64 limit: ~60MB (~45MB after encoding)
        const maxBase64Size = 45 * 1024 * 1024 // 45MB safe limit
        if (buffer.length > maxBase64Size) {
          console.log(`‚ö†Ô∏è File too large (${finalSizeMB}MB > 45MB), compressing harder...`)
          
          // ‡∏ö‡∏µ‡∏ö‡πÅ‡∏£‡∏á‡∏™‡∏∏‡∏î: 2000px, quality 60
          buffer = await sharp(buffer, { failOnError: false })
            .resize(2000, 2000, { fit: 'inside', withoutEnlargement: true })
            .jpeg({ quality: 60, mozjpeg: true })
            .toBuffer()
          
          finalSizeMB = (buffer.length / (1024 * 1024)).toFixed(2)
          mimeType = 'image/jpeg'
          console.log(`‚úÖ Extra compression: ${finalSizeMB}MB`)
          
          // ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÉ‡∏´‡∏ç‡πà ‚Üí error
          if (buffer.length > maxBase64Size) {
            throw new Error(`File too large after compression: ${finalSizeMB}MB (max 45MB for upload)`)
          }
        }
        
      } catch (sharpError) {
        console.error(`‚ö†Ô∏è Sharp processing failed:`, sharpError)
        // ‡∏ñ‡πâ‡∏≤ Sharp ‡∏•‡πâ‡∏° ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JPEG ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        try {
          buffer = await sharp(buffer, { failOnError: false })
            .jpeg({ quality: 70 })
            .toBuffer()
          mimeType = 'image/jpeg'
          console.log(`‚úÖ Fallback: Converted to JPEG`)
        } catch {
          // ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á fail ‚Üí ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
          console.log(`‚ö†Ô∏è Using original buffer`)
        }
      }
      
      const base64 = `data:${mimeType};base64,${buffer.toString('base64')}`
      
      // Upload to Cloudinary with retry
      console.log(`‚òÅÔ∏è Uploading to Cloudinary...`)
      try {
        const url = await uploadBase64ToCloudinary(base64, 'hotelplus-v2')
        console.log(`‚úÖ Success: ${url}`)
        return NextResponse.json({ url })
      } catch (uploadError) {
        console.error(`‚ùå Cloudinary upload failed:`, uploadError)
        if (attempt < maxAttempts) {
          console.log(`üîÑ Retrying upload...`)
          await new Promise(resolve => setTimeout(resolve, 2000))
          continue
        }
        throw uploadError
      }
      
    } catch (error) {
      console.error(`‚ùå Error (attempt ${attempt}/${maxAttempts}):`, error)
      
      if (attempt >= maxAttempts) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error'
        return NextResponse.json(
          { error: `Failed after ${maxAttempts} attempts: ${errorMessage}` },
          { status: 500 }
        )
      }
      
      // Wait before retry
      await new Promise(resolve => setTimeout(resolve, 2000))
    }
  }
  
  return NextResponse.json({ error: 'Failed to process file' }, { status: 500 })
}
