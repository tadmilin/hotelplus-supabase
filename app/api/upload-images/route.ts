import { NextRequest, NextResponse } from 'next/server'
import { v2 as cloudinary } from 'cloudinary'
import sharp from 'sharp'

cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET,
})

// üî• Increase limits for large image uploads (Hobby plan max: 60s)
export const maxDuration = 60 // 60 seconds (Vercel Hobby limit)
export const dynamic = 'force-dynamic'

// Helper function to sanitize filename
function sanitizeFilename(filename: string): string {
  return filename
    .replace(/[^a-zA-Z0-9._-]/g, '_') // Replace special chars with underscore
    .replace(/_{2,}/g, '_') // Replace multiple underscores with single
    .replace(/^_+|_+$/g, '') // Remove leading/trailing underscores
}

// üî• Smart compression ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô
async function smartCompress(buffer: Buffer): Promise<{ buffer: Buffer; mimeType: string }> {
  // üî• STRATEGY: ‡∏ö‡∏µ‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10MB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cloudinary
  // ‡πÅ‡∏ï‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î dimension ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô‡∏ä‡∏±‡∏î
  
  const targetSizeMB = 10 // Cloudinary free plan limit
  const sizeMB = buffer.length / (1024 * 1024)
  
  // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏ä‡πâ quality ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
  if (sizeMB <= targetSizeMB) {
    const result = await sharp(buffer, { failOnError: false })
      .jpeg({ quality: 95, mozjpeg: true }) // üî• quality ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
      .toBuffer()
    return { buffer: result, mimeType: 'image/jpeg' }
  }
  
  // üî• ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà: ‡πÉ‡∏ä‡πâ progressive compression
  // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å quality ‡∏™‡∏π‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏î‡∏•‡∏á‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
  const qualityLevels = [90, 85, 80, 75, 70, 65]
  
  for (const quality of qualityLevels) {
    const result = await sharp(buffer, { failOnError: false })
      .jpeg({ quality, mozjpeg: true })
      .toBuffer()
    
    const resultSizeMB = result.length / (1024 * 1024)
    console.log(`  üì¶ Quality ${quality}: ${resultSizeMB.toFixed(2)}MB`)
    
    if (resultSizeMB <= targetSizeMB) {
      return { buffer: result, mimeType: 'image/jpeg' }
    }
  }
  
  // üî• ‡∏¢‡∏±‡∏á‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ? ‡∏•‡∏î dimension ‡πÅ‡∏ï‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô (4K)
  const result = await sharp(buffer, { failOnError: false })
    .resize(3840, 3840, { fit: 'inside', withoutEnlargement: true })
    .jpeg({ quality: 80, mozjpeg: true })
    .toBuffer()
  
  return { buffer: result, mimeType: 'image/jpeg' }
}

export async function POST(req: NextRequest) {
  try {
    const formData = await req.formData()
    const files = formData.getAll('files') as File[]

    if (files.length === 0) {
      return NextResponse.json({ error: 'No files uploaded' }, { status: 400 })
    }

    const uploadedImages = []

    for (const file of files) {
      const sanitizedName = sanitizeFilename(file.name)
      const bytes = await file.arrayBuffer()
      let buffer = Buffer.from(bytes)
      const originalSizeMB = (buffer.length / (1024 * 1024)).toFixed(2)
      
      console.log(`üì§ Uploading: ${sanitizedName} (original: ${file.name}, ${originalSizeMB}MB, type: ${file.type})`)
      
      // üî• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô HEIC/HEIF ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà
      const isHeic = file.type === 'image/heic' || 
                     file.type === 'image/heif' ||
                     file.name.toLowerCase().endsWith('.heic') ||
                     file.name.toLowerCase().endsWith('.heif')
      
      const needsProcessing = buffer.length > 10 * 1024 * 1024 || isHeic
      
      let mimeType = 'image/jpeg'
      
      if (needsProcessing) {
        console.log(`üîÑ Processing large/HEIC image: ${sanitizedName}`)
        
        try {
          // üî• ‡πÉ‡∏ä‡πâ smart compression ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô
          const result = await smartCompress(buffer)
          buffer = Buffer.from(result.buffer)
          mimeType = result.mimeType
          
          const compressedSizeMB = (buffer.length / (1024 * 1024)).toFixed(2)
          console.log(`‚úÖ Smart compressed: ${originalSizeMB}MB ‚Üí ${compressedSizeMB}MB`)
        } catch (err) {
          console.error(`‚ùå Failed to process ${sanitizedName}:`, err)
          throw new Error(`Failed to process image: ${sanitizedName}`)
        }
      } else {
        // üî• ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å: ‡πÅ‡∏Ñ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JPEG quality ‡∏™‡∏π‡∏á
        try {
          const processed = await sharp(buffer, { failOnError: false })
            .jpeg({ quality: 95, mozjpeg: true })
            .toBuffer()
          buffer = Buffer.from(processed)
        } catch (err) {
          console.log(`‚ö†Ô∏è Sharp failed, using original:`, err)
        }
      }
      
      const base64 = buffer.toString('base64')
      const dataUri = `data:${mimeType};base64,${base64}`

      const result = await cloudinary.uploader.upload(dataUri, {
        folder: 'hotelplus-v2',
        resource_type: 'image',
        public_id: `${Date.now()}_${sanitizedName.replace(/\.[^/.]+$/, '')}`, // Use sanitized name without extension
      })

      uploadedImages.push({
        id: result.public_id,
        name: file.name, // Keep original name for display
        url: result.secure_url,
        thumbnailUrl: result.secure_url.replace('/upload/', '/upload/w_300,h_300,c_fill/'),
      })
      
      console.log(`‚úÖ Uploaded successfully: ${sanitizedName}`)
    }

    return NextResponse.json({ 
      success: true, 
      images: uploadedImages 
    })
  } catch (error) {
    console.error('Upload error:', error)
    return NextResponse.json(
      { error: 'Failed to upload images' },
      { status: 500 }
    )
  }
}
